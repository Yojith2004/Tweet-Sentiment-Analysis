{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4140,"sourceType":"datasetVersion","datasetId":2477}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Loading the Dataset**","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv',encoding='ISO-8859-1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Preprocessing**","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clearly, the dataset does not contain the column/feature names, so I assigned names to the features.","metadata":{}},{"cell_type":"code","source":"col_names=['Target','ID','Date','Flag','User','Text']\ndf=pd.read_csv('/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv', names=col_names,encoding='ISO-8859-1')\ndf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking for Missing Values\ndf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Target'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Renaming the positive class from 4 to 1\n\n0 → Negative Tweet, 1 → Positive Tweet.","metadata":{}},{"cell_type":"code","source":"df.replace({'Target':{4:1}}, inplace=True)\ndf['Target'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x=df['Target'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Stemming**\n\nUsing the stemming technique in order to reduce a word to its root form.","metadata":{}},{"cell_type":"code","source":"import re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nps=PorterStemmer()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('stopwords')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(stopwords.words('english'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def stemming(content):\n    stem_content=re.sub('[^a-zA-Z]',' ',content)\n    stem_content=stem_content.lower()\n    stem_content=stem_content.split()\n    stem_content=[ps.stem(word) for word in stem_content if not word in stopwords.words('english')]\n    stem_content=' '.join(stem_content)\n    \n    return stem_content","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['stem_content']=df['Text'].apply(stemming)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Separating Feature and Target Variables**","metadata":{}},{"cell_type":"code","source":"X=df['stem_content'].values\nY=df['Target'].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Splitting the Data into Training and Testing Sets**\n\nTo ensure that the distribution of the target variable Y is consistent in both the training and testing sets, I used stratify=Y during the data split.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Transforming Text Data with TF-IDF Vectorization**\n\nUsing TF-IDF Vectorization in order to convert the text data into numerical features.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nv=TfidfVectorizer()\nX_train=v.fit_transform(x_train)\nX_test=v.transform(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model Training and Evaluation**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=LogisticRegression(max_iter=1000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Accuracy score:',accuracy_score(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}